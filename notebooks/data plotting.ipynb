{
 "metadata": {
  "name": "data plotting"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython import parallel\n",
      "from glob import glob\n",
      "from datetime import datetime\n",
      "from matplotlib import pylab as plt\n",
      "from mpl_toolkits.basemap import Basemap\n",
      "\n",
      "c = parallel.Client()\n",
      "dv = c[:]\n",
      "dv.block = True\n",
      "with dv.sync_imports():\n",
      "    import numpy\n",
      "    from netCDF4 import Dataset, date2num\n",
      "    import cdms2\n",
      "\n",
      "data_dir = '/data/cmip5/output1/MOHC/HadGEM2-ES/rcp85/mon/atmos/' \\\n",
      "           'Amon/r1i1p1/v20111215/tas/'\n",
      "fs = glob(data_dir + 'tas_Amon_HadGEM2-ES_rcp85_r1i1p1_*-*.nc')\n",
      "t0 = datetime(2010, 1, 1)\n",
      "t1 = datetime(2010, 2, 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "importing numpy on engine(s)\n",
        "importing Dataset,date2num from netCDF4 on engine(s)\n",
        "importing cdms2 on engine(s)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dv.sync_imports():\n",
      "    import cf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "importing cf on engine(s)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_netcdf4 ():\n",
      "    datasets = []\n",
      "    for f in fs:\n",
      "        d = Dataset(f)\n",
      "        time = d.variables['time']\n",
      "        n = len(time)\n",
      "        if n > 0:\n",
      "            this_t0 = date2num(t0, time.units, time.calendar)\n",
      "            this_t1 = date2num(t1, time.units, time.calendar)\n",
      "            if time[n - 1] >= this_t0 and time[0] < this_t1:\n",
      "                # add data for each time in the right range\n",
      "                lat = d.variables['lat']\n",
      "                lon = d.variables['lon']\n",
      "                tas = d.variables['tas']\n",
      "                for i_t, t in enumerate(time[:]):\n",
      "                    if this_t0 <= t < this_t1:\n",
      "                        datasets.append((t, lon[:], lat[:], tas[i_t,:,:]))\n",
      "        d.close()\n",
      "    return datasets\n",
      "\n",
      "def get_time_range_cf (time):\n",
      "    f = cf.Coordinate()\n",
      "    f._data = cf.Data(numpy.array([0, 0]))\n",
      "    u = cf.Units('months since 2010-1-1')\n",
      "    u.calendar = time.calendar\n",
      "    f.override_Units(u)\n",
      "    f.slice[:] = [0, 1]\n",
      "    f.units = time.units\n",
      "    return f.array\n",
      "\n",
      "def get_data_cf ():\n",
      "    fields = cf.read(fs)\n",
      "    datasets = []\n",
      "    for f in fields:\n",
      "        if f.name() == 'air_temperature':\n",
      "            s = f.space\n",
      "            time = s['dim0']\n",
      "            if time.size == 0:\n",
      "                continue\n",
      "            else:\n",
      "                t_1d = time.size == 1\n",
      "            this_t0, this_t1 = get_time_range_cf(time)\n",
      "            time = time.varray\n",
      "            if t_1d:\n",
      "                time = [time]\n",
      "            if time[-1] >= this_t0 and time[0] < this_t1:\n",
      "                # add data for each time in the right range\n",
      "                lat = s['dim1']\n",
      "                lon = s['dim2']\n",
      "                for i_t, t in enumerate(time):\n",
      "                    if this_t0 <= t < this_t1:\n",
      "                        if t_1d:\n",
      "                            tas = f.slice[:,:].array\n",
      "                        else:\n",
      "                            tas = f.slice[i_t,:,:].array[0]\n",
      "                        datasets.append((t, lon.array, lat.array, tas))\n",
      "    cf.close()\n",
      "    return datasets\n",
      "\n",
      "def get_data_cdms2 ():\n",
      "    datasets = []\n",
      "    for f in fs:\n",
      "        f = cdms2.open(f)\n",
      "        tas = f('tas')\n",
      "        time, lat, lon = tas.getAxisList()\n",
      "        if len(time) > 0:\n",
      "            this_t0 = date2num(t0, time.units, time.calendar)\n",
      "            this_t1 = date2num(t1, time.units, time.calendar)\n",
      "            if time[-1] >= this_t0 and time[0] < this_t1:\n",
      "                # add data for each time in the right range\n",
      "                for i_t, t in enumerate(time):\n",
      "                    if this_t0 <= t < this_t1:\n",
      "                        tas_data = numpy.array(tas[i_t,:,:])\n",
      "                        datasets.append((t, lon[:], lat[:], tas_data))\n",
      "        f.close()\n",
      "    return datasets\n",
      "\n",
      "def get_data (method, in_parallel):\n",
      "    if method == 0:\n",
      "        get_data = get_data_netcdf4\n",
      "    elif method == 1:\n",
      "        get_data = get_data_cf\n",
      "    else: # method == 2\n",
      "        get_data = get_data_cdms2\n",
      "    if in_parallel:\n",
      "        dv.scatter('fs', fs)\n",
      "        dv.push({'t0': t0, 't1': t1})\n",
      "        if method == 1:\n",
      "            dv['get_time_range_cf'] = get_time_range_cf\n",
      "        sum = __builtin__.sum # not sure where sum becomes numpy.sum...\n",
      "        datasets = sum(dv.apply(get_data), [])\n",
      "    else:\n",
      "        datasets = serial_data = get_data()\n",
      "    return datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# time some data processing in serial and parallel\n",
      "all_datasets = []\n",
      "for method in xrange(3):\n",
      "    method_name = ('netcdf', 'cf', 'cdat_lite')[method]\n",
      "    # check method is supported\n",
      "    try:\n",
      "        if method == 0:\n",
      "            Dataset\n",
      "            dv.execute('Dataset')\n",
      "        elif method == 1:\n",
      "            cf\n",
      "            dv.execute('cf')\n",
      "        else: # method == 2\n",
      "            cdms2\n",
      "            dv.execute('cdms2')\n",
      "    except (NameError, parallel.CompositeError):\n",
      "        print 'unsupported method:', method_name\n",
      "        continue\n",
      "    # run computation\n",
      "    for in_parallel in (False, True):\n",
      "        print method_name, ('serial', 'parallel')[in_parallel]\n",
      "        %timeit all_datasets.append(get_data(method, in_parallel))\n",
      "# check all methods return the same data\n",
      "print 'results the same:',\n",
      "print all(all([(x == y).all() if isinstance(x, numpy.ndarray) else x == y \\\n",
      "               for x, y in zip(d1, d2)] \\\n",
      "              for d1, d2 in zip(all_datasets[i], all_datasets[i + 1])) \\\n",
      "          for i in xrange(len(all_datasets) - 1))\n",
      "if all_datasets:\n",
      "    datasets = all_datasets[0]\n",
      "del all_datasets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "netcdf serial\n",
        "100 loops, best of 3: 18.2 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "netcdf parallel\n",
        "10 loops, best of 3: 45.5 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cf serial\n",
        "1 loops, best of 3: 435 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cf parallel\n",
        "1 loops, best of 3: 430 ms per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cdat_lite serial\n",
        "1 loops, best of 3: 1.57 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "cdat_lite parallel\n",
        "1 loops, best of 3: 1.12 s per loop"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "results the same: True\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# standard plot\n",
      "num_levels = 100\n",
      "x, y, z = datasets[0][1:]\n",
      "plot = plt.contourf(x, y, z, num_levels)\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Mercator projection\n",
      "lon, lat, tas = datasets[0][1:]\n",
      "m = Basemap(projection = 'merc', llcrnrlat = -80, urcrnrlat = 80,\n",
      "            llcrnrlon = lon[0], urcrnrlon = lon[-1], lat_ts = 0)\n",
      "m.drawcoastlines()\n",
      "#m.drawparallels(range(-90, 90, 30))\n",
      "#m.drawmeridians(range(-0, 360, 30))\n",
      "x, y = m(*np.meshgrid(lon, lat))\n",
      "m.contourf(x, y, tas, 100)\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    }
   ],
   "metadata": {}
  }
 ]
}