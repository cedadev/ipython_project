#! /usr/bin/env python

# TODO:
# - handle user@host-style hostnames properly
# - restart processes if they die?  Retransfer connection files if needed (shouldn't matter they've already been changed).
# - option to not use ssh?
#   - have nossh key, list of hosts
#   - plus ssh[default:true] option per nbclient
#   - still have to transfer files, run setup commands over ssh - note in help
#   - just don't have tunnels from these hosts, and have ssh="" in confiles

from sys import exit, version_info

ERR_ENV = 1
ERR_ARGS = 2 # optparse uses this
ERR_CONF = 3
ERR_EXEC = 4
ERR_IO = 5


def err (msg, code):
    """Print an error message and exit."""
    print 'error:', msg
    exit(code)


# do version check here, since even imports are version-dependent
if version_info < (2, 5):
    print err(ERR_ENV, 'Python version is too low; at least 2.5 is required')

from time import strftime, sleep, time
from signal import signal, SIGINT, SIGTERM, SIGHUP, SIGKILL
import optparse
from random import sample
import os
from collections import defaultdict
from tempfile import mkstemp
from shutil import copyfile
from subprocess import Popen, PIPE
import shlex
import socket
from pipes import quote as quote_single
try:
    import json
except ImportError:
    try:
        import simplejson as json
    except ImportError:
        err(ERR_ENV, 'to use this with Python 2.5, simplejson is required')

USAGE = '%prog [OPTIONS] CONFIG_FILE'
HELP = '''
This script starts an IPython cluster across multiple machines according to the
configuration file CONFIG_FILE.  It requires Python 2.5 or later 2.x, and the
development version of IPython.  If using Python 2.5, the simplejson package
is required.

CONFIG_FILE is a JSON file containing a dict with keys:
    controller: controller host.
    engines [optional]: a dict of engines to run.  Keys are hosts and values
                        are the numbers of engines to run.
    notebooks [optional]: a list of hosts to run notebook servers on.
    paths [optional]: a dict of paths to IPython executables.  Keys are hosts
                      and values are {executable: path}.  Any undefined paths
                      are assumed to be on the shell's path.  Executables are
                      used for:
        ipcontroller: the controller.
        ipengine: all engines.
        python: all hosts running a component except localhost.
        ipython: all notebooks, and all engines with a different host or
                 profile to the controller.
    ports [optional]: a dict of port ranges to assign ports in.  Keys are hosts
                      and values are [min_port, max_port], where endpoints are
                      included (or just [min_port]).  This does not apply to
                      the notebook server's port.

In each case, a host is a dict with keys:
    host: the hostname or IP, as you would pass to SSH to connect to it,
          excluding the port (user@host is not currently supported).  This may
          be user@host, but see a known issue regarding this below.
    port [default = 8888]: Port to listen on for notebook connections.
    profile [default = 'default']: IPython profile to use for this process.
    options: a list of extra command-line options to pass to the notebook
             server (should not contain --port).  --no-browser is appended
             automatically if this is not running on the local machine.
    clients: a list of hosts to forward the notebook's port to.

The accepted keys depends on the type of host:
    notebooks: host, port, profile, options, clients.
    notebook clients: host, port (port is the port on the client to bind the
                      notebook server's port to).
    paths hosts: host.
    all others: host, profile.

Hosts may also be given as strings or lists.  Lists contain values in the same
order as keys are listed above, and possibly truncated to exclude any trailing
optional arguments.  Strings contain the same arguments separated by `:'
characters; leave sections empty for defaults, and note that this form cannot
handle arguments that are lists.  For example, the following are equivalent:
    "somehost"
    "somehost:default"
    ["somehost"]
    ["somehost", "default"]
    {"host": "somehost"}
    {"host": "somehost", "profile": "default"}

A full example, which runs the controller, notebook server and 2 engines on
`host1', 4 engines on `host2' and 4 engines locally:

{
    "controller": "host1:another_profile",
    "engines": {
        "localhost:remote_profile": 4,
        "host1": 2,
        "host2": 4
    },
    "notebooks": [
        {
            "host": "host1",
            "port": 5000,
            "options": ["--notebook-dir=~/ipython", "--pylab=inline"],
            "clients": ["localhost:5000"]
        }
    ],
    "paths": {
        "host1": {
            "ipcontroller": "/opt/ipython/bin/ipcontroller",
            "ipengine": "/opt/ipython/bin/ipengine",
            "ipython": "/opt/ipython/bin/ipython"
        },
        "host2": {
            "python": "python2"
        }
    }
}

Log files from every process this script runs are saved in the working
directory; if something doesn't work, look through these first.

Known issues:
 - SSH connections from the local machine to any host and from any host to the
   controller's should be passwordless - otherwise, you'll probably have to
   enter passwords lots of times, and things might get messy.
 - Things will go wrong if your shell configuration files on any remote host
   print anything to stdout.
 - Depending on your configuration, a /lot/ of log files may be created in the
   working directory while running.
 - If a host is given as user@host, every instance of the host must have the
   same user explicitly defined.

To stop this script and all running components, send one of SIGINT (ctrl-C),
SIGTERM or SIGHUP.

The exit status in the case of an error is:
    1: insufficient dependencies
    2: incorrect arguments
    3: invalid configuration file
    4: couldn't execute a command
    5: local I/O error'''

POLL_WAIT = .1
TUNNEL_WAIT = 1
WAIT_TO_KILL = 5
ENGINE = 1
CLIENT = 2
ALL = ENGINE | CLIENT
IDENT_TO_STR = {ENGINE: 'engine', CLIENT: 'client', ALL: 'all'}
PORTS = {
    'control': ((CLIENT, 'control'), (ENGINE, 'control')),
    'task': ((CLIENT, 'task'), (ENGINE, 'task')),
    'mux': ((CLIENT, 'mux'), (ENGINE, 'mux')),
    'regport': ((ALL, 'registration'),),
    'iopub': ((CLIENT, 'iopub'), (ENGINE, 'iopub')),
    'hb': ((ENGINE, 'hb_ping'), (ENGINE, 'hb_pong')),
    'notifier_port': ((CLIENT, 'notification'),)
}
COMPONENT_TIMEOUT = 10
# each is (stdout, stderr), each a list of strings to look for
SUCCESS_MATCH = {
    'controller': ('[scheduler] Scheduler started',),
    'tunnel': ('[start-cluster] tunnel: success',),
    'engine': ('[IPEngineApp] Registering with controller',),
    'notebook': ('[NotebookApp] The IPython Notebook is running at:',),
}
ERROR_MATCH = {
    None: ('Host key verification failed.', 'Permission denied'), # all
    'controller': ('registration::purging stalled registration:',),
    'tunnel': ('bind: Address already in use',
               'channel_setup_fwd_listener: cannot listen to port:',
               'Could not request local forwarding.'),
    'engine': (),
    'notebook': ('is already in use, trying another random port.',)
}


def quote (args):
    """pipes.quote wrapper to handle lists of args and empty args."""
    if isinstance(args, basestring):
        return quote_single(args) if args else '""'
    else:
        return [quote_single(s) if s else '""' for s in args]


class PreformattedFormatter (optparse.IndentedHelpFormatter):
    """optparse text formatter for preformatted description text."""

    def format_description (self, desc):
        return desc.rstrip().lstrip('\n\r') + '\n'


class Launcher:
    """Handles starting up a cluster over SSH, including forwarding ports."""

    def __init__ (self, log_dir, preserve_logs, startup_delay, quiet, debug):
        self.log_dir = log_dir
        self.preserve_logs = preserve_logs
        self.startup_delay = startup_delay
        self.quiet = quiet
        self.debug = debug
        self.hosts = {}
        self.ipy_dirs = {}
        self.stopping = False
        self._stopped = True
        self._starting = False
        # add localhost so that we don't ssh to aliases for it to check their
        # IPs
        self.host('localhost')

    def load_config (self, fn):
        # load configuration file
        try:
            f = open(fn)
            try:
                config = json.load(f)
            finally:
                f.close()
        except IOError:
            err('configuration file not found', ERR_ARGS)
        except ValueError:
            err('invalid configuration file: not valid JSON', ERR_CONF)
        # check keys
        if not isinstance(config, dict) or 'controller' not in config:
            err('invalid configuration file: a controller is required', ERR_CONF)
        items = (('engines', dict), ('notebooks', list),
                ('paths', dict), ('ports', dict))
        for k, t in items:
            if not isinstance(config.setdefault(k, t()), t):
                msg = 'invalid configuration file: %s must be a %s'
                err(msg % (k, t.__name__), ERR_CONF)
        ks = ('controller',) + zip(*items)[0]
        return [config[k] for k in ks]

    def launch (self, fn):
        """Start the cluster.

Takes the configuration file path.

"""
        if self.stopping:
            raise RuntimeError('can\'t launch while stopping')
        if not self._stopped:
            raise RuntimeError('already running: can\'t launch again')
        self._stopped = False
        # load config
        controller, engines, notebooks, paths, ports = self.load_config(fn)
        # initialise things
        self.log_prefix = os.path.join(self.log_dir, strftime('%F-%T'))
        self.ipy_paths = {}
        self.port_ranges = defaultdict(lambda: (0, 2 ** 16 - 1), {})
        self.ports = {}
        self.processes = {}
        self.log_files = {}
        self.open_fs = []
        self._has_con_file = {ENGINE: [], CLIENT: []}
        self.add_paths(paths)
        self.add_port_ranges(ports)
        c_host, c_profile = self.host(controller)
        # get hosts that will connect to controller, sort by host, and disallow
        # using notebook ports for controller connections
        toctrl_hosts = {}
        hostnames = []
        self._used_ports = used_ports = {}
        for t, hosts in ((ENGINE, engines), (CLIENT, notebooks)):
            for host in hosts:
                data = self.host(host, None if t == ENGINE else 'nb')
                host = data[0]
                hostnames.append(host)
                if t == CLIENT:
                    # add notebook port to list, and check for conflicts
                    port = data[1]
                    this_used = used_ports.setdefault(host, [])
                    if port in this_used:
                        msg = 'multiple components are using port %s on %s'
                        self.bail_out(msg % (port, host), ERR_CONF)
                    this_used.append(port)
                if host != c_host:
                    toctrl_hosts[host] = toctrl_hosts.get(host, 0) | t
        hostnames = list(set(hostnames))
        # make controller host first, if present
        if c_host in hostnames:
            hostnames.insert(0, hostnames.pop(hostnames.index(c_host)))
        # notebook clients
        connecting_hosts = {}
        for notebook in notebooks:
            data = self.host(notebook, 'nb')
            n_host, n_port = data[:2]
            hosts = connecting_hosts.setdefault(n_host, {})
            for client in data[4]:
                host, port = self.host(client, 'nbclient')
                # check for conflicts
                this_used = used_ports.setdefault(host, [])
                if port in this_used:
                    msg = 'multiple components are using port %s on %s'
                    self.bail_out(msg % (port, host), ERR_CONF)
                this_used.append(port)
                if host != n_host:
                    hosts.setdefault(host, []).append((port, n_port))
        # controller: pass options for ports so we know what they are
        port_opts = self.get_ports(c_host, ALL, 'cmdline')
        cmd = [self.get_path(c_host, 'ipcontroller'),
               '--profile=%s' % c_profile] + port_opts
        c_ident = self.run_on(c_host, cmd, 'controller')
        # get ports to forward to controller
        c_ports = self.get_ports(c_host, ALL, 'ident')
        for host, types in toctrl_hosts.iteritems():
            ports = self.get_ports(host, types, 'ident')
            toctrl_hosts[host] = [(ports[ident], c_ports[ident])
                                  for ident in ports]
        toctrl_hosts_new = connecting_hosts.setdefault(c_host, {})
        for host in toctrl_hosts:
            toctrl_hosts_new.setdefault(host, []).extend(toctrl_hosts[host])
        # forward ports
        t_idents = []
        for to_host, hosts in connecting_hosts.iteritems():
            for host, ports in hosts.iteritems():
                ident = self.tunnel(host, to_host, ports)
                t_idents.append(ident)
        # wait for controller to initialise
        self.wait_for(('controller', c_ident))
        # wait for tunnels
        self.wait_for(('tunnel', t_idents))
        # for both engines and notebooks, some might share a filesystem with
        # the controller, so to avoid connection file clashes, start the
        # controller's first, then those on each host in turn
        for host in hostnames:
            # engines
            e_idents = []
            done = {}
            for engine, num in engines.iteritems():
                e_host, e_profile = self.host(engine)
                if e_host != host:
                    continue
                self.copy_con_file(c_host, c_profile, e_host, e_profile,
                                   ENGINE)
                for i in xrange(num):
                    n = done.get(e_profile, 0)
                    cmd = (self.get_path(e_host, 'ipengine'),
                           '--profile=%s' % e_profile)
                    ident = '%s-engine-%s' % (e_profile, n + i)
                    e_idents.append(self.run_on(e_host, cmd, ident))
                    if e_host != 'localhost':
                        sleep(self.startup_delay)
                done[e_profile] = num
            # notebooks
            n_idents = []
            done = {}
            for notebook in notebooks:
                n_host, n_port, n_profile, opts = self.host(notebook, 'nb')[:4]
                if n_host != host:
                    continue
                self.copy_con_file(c_host, c_profile, n_host, n_profile,
                                   CLIENT)
                opts = [str(o) for o in opts]
                if n_host != 'localhost' and '--no-browser' not in opts:
                    # running remotely, so running a browser is silly
                    opts.append('--no-browser')
                cmd = [self.get_path(n_host, 'ipython'), 'notebook',
                       '--profile=%s' % n_profile, '--port=%s' % n_port] + opts
                i = done.get(n_profile, 0)
                ident = '%s-notebook-%s' % (n_profile, i)
                n_idents.append(self.run_on(n_host, cmd, ident))
                done[n_profile] = i + 1
                if n_host != 'localhost':
                    sleep(self.startup_delay)
            # wait for this host's components to read their connection files
            # before we start anything on the next host, so that we haven't
            # modified them before this host has read them
            wait_for = []
            if e_idents:
                wait_for.append(('engine', e_idents))
            if n_idents:
                wait_for.append(('notebook', n_idents))
            self.wait_for(*wait_for)
        print 'initialisation finished'

    def wait (self):
        """Do nothing until the launcher is stopped or a subprocess dies."""
        # this should remain a reference to the process list
        ps = self.processes
        while True:
            # quit if stopped
            if self.stopping or self._stopped:
                exit(0)
            # or nothing is running
            if not ps:
                err('no processes running: stopping...', ERR_EXEC)
            # or any subprocesses have stopped
            finished = [i for i, (p, w) in ps.iteritems()
                        if not w and p.poll() is not None]
            if finished:
                msg = 'one or more processes died:\n\t' + '\n\t'.join(finished)
                self.bail_out(msg, ERR_EXEC)
            sleep(1)

    def stop (self, *args):
        """Stop all subprocesses."""
        while self._starting:
            sleep(POLL_WAIT)
        if self.stopping or self._stopped:
            return
        print 'stopping processes...'
        self.stopping = True
        # try TERM
        ps = self.processes
        for i, (p, w) in ps.iteritems():
            if p.poll() is None:
                print '[stop]', i
                try:
                    try:
                        p.terminate()
                    except AttributeError:
                        os.kill(p.pid, SIGTERM)
                except OSError:
                    # already finished
                    pass
        # wait for a while
        for j in xrange(int(WAIT_TO_KILL / POLL_WAIT)):
            if any(p.poll() is None for i, (p, w) in ps.iteritems()):
                sleep(POLL_WAIT)
            else:
                break
        # resort to KILL for still-running processes
        for i, (p, w) in ps.iteritems():
            if p.poll() is None:
                print '[kill]', i
                try:
                    try:
                        p.kill()
                    except AttributeError:
                        os.kill(p.pid, SIGKILL)
                except OSError:
                    # already finished
                    pass
        # close/delete log files
        delete = not self.preserve_logs
        for f in self.open_fs:
            f.close()
            if delete:
                try:
                    os.remove(f.name)
                except OSError:
                    pass
        self.stopping = False
        self._stopped = True

    def bail_out (self, msg, code):
        """Die gracefully."""
        print 'error:', msg
        self.stop()
        exit(code)

    def _close_fs (self, all_fs):
        """Used by wait_for."""
        for fs in all_fs.itervalues():
            for f in fs:
                f.close()

    def _wait_for (self, groups, all_fs):
        """Like wait_for, but also takes files to read from.

Returns (err_msg, err_code, allow_for_stop) or None.

"""
        t0 = time()
        ps = self.processes
        # wait for success/error strings
        done = False
        got_timeout = True
        while not done:
            if time() - t0 > COMPONENT_TIMEOUT:
                done = True
                # but still do one more check
            g_rm = []
            for t, idents in groups:
                success = SUCCESS_MATCH[t]
                error = ERROR_MATCH[t] + ERROR_MATCH[None]
                i_rm = []
                for ident in idents:
                    p = ps[ident][0]
                    if p.poll() is not None:
                        # process has finished
                        return ('process ended unexpectedly: %s' % ident,
                                ERR_EXEC, True)
                    fs = all_fs[ident]
                    # check for strings
                    p_done = False
                    for f in fs:
                        l = f.readline()
                        while l:
                            l = l.strip()
                            for is_bad, checks in enumerate((success, error)):
                                # check in this line
                                for s in checks:
                                    if s in l:
                                        if is_bad:
                                            # wow, indent
                                            self._close_fs(all_fs)
                                            msg = 'process %s says, \'%s\''
                                            return (msg % (ident, l), ERR_EXEC,
                                                    False)
                                        else:
                                            # success: done with this process
                                            if self.debug:
                                                msg = 'success: %s says, ' \
                                                      '\'%s\' after %s seconds'
                                                print msg % (ident, l,
                                                             time() - t0)
                                            p_done = True
                                            break
                            l = f.readline()
                    # horrible (no, not the comment)
                            if p_done:
                                break
                        if p_done:
                            break
                    if p_done:
                        i_rm.append(ident)
                for ident in i_rm:
                    idents.remove(ident)
                if not idents:
                    g_rm.append((t, idents))
            for g in g_rm:
                groups.remove(g)
            if not groups:
                # everything was successful
                done = True
                got_timeout = False
            sleep(POLL_WAIT)
        if got_timeout:
            msg = 'components didn\'t start in %s seconds:\n\t'
            msg += '\n\t'.join(sum((idents for t, idents in groups), []))
            return (msg % COMPONENT_TIMEOUT, ERR_EXEC, True)

    def wait_for (self, *groups):
        """Wait for a process to do something.

Each argument is (type, idents), idents a process identifier to watch, or a
list of more than one.

"""
        groups = [(t, list(idents if isinstance(idents, list) else [idents]))
                  for t, idents in groups]
        if not self.quiet:
            for t, idents in groups:
                for ident in idents:
                    print '[wait]', ident
        # open files
        all_log_files = self.log_files
        all_fs = {}
        for t, idents in groups:
            for ident in idents:
                all_fs[ident] = fs = []
                log_files = all_log_files[ident]
                for i, log_file in enumerate(all_log_files[ident]):
                    try:
                        f = open(log_file)
                    except IOError:
                        msg = 'couldn\'t open log file for reading: \'%s\''
                        self.bail_out(msg % log_file, ERR_IO)
                        self._close_fs(all_fs)
                        # current file wasn't opened
                    else:
                        fs.append(f)
        error = self._wait_for(groups, all_fs)
        # clean up
        self._close_fs(all_fs)
        if error is not None:
            msg, code, check_stop = error
            if check_stop and (self.stopping or self._stopped):
                exit(0)
            self.bail_out(msg, code)

    def mk_log_files (self, *data):
        """Return stdout/stderr log file names for a process.

Takes any number of arguments, which are just things that identify this
process.

Returns ((stdout, stderr), ident), where ident is a string identifier for this
process.

"""
        nice_data = []
        for s in data:
            nice_s = s.replace('%', '%%').replace('\0', '%')
            nice_data.append(nice_s.replace('#', '##').replace('/', '#'))
        ident = '-'.join(nice_data)
        log_file = '%s-%s-%s' % (self.log_prefix, ident, '%s')
        fs = [log_file % 'stdout', log_file % 'stderr']
        exists = os.path.exists
        while exists(fs[0] + '.log') or exists(fs[1] + '.log'):
            fs[0] += '_'
            fs[1] += '_'
        assert ident not in self.processes
        fs[0] += '.log'
        fs[1] += '.log'
        return (fs, ident)

    def add_paths (self, paths):
        """Store paths from the configuration file."""
        stored = self.ipy_paths
        for host, this_paths in paths.iteritems():
            if not isinstance(this_paths, dict):
                msg = 'invalid configuration file: paths values must be ' \
                      'dict, got %s for host \'%s\''
                self.bail_out(msg % (repr(this_paths), host), ERR_CONF)
            host = self.host(host, 'path')[0]
            this_stored = stored.setdefault(host, {})
            for cmd, path in this_paths.iteritems():
                this_stored[cmd] = str(path)

    def add_port_ranges (self, ports):
        """Store port ranges from the configuration file."""
        stored = self.port_ranges
        for host, this_ports in ports.iteritems():
            if not isinstance(this_ports, list) \
               or len(this_ports) not in (1, 2) \
               or not all(isinstance(p, int) for p in this_ports):
                msg = 'invalid configuration file: ports values must be ' \
                      '1- or 2-length list of ints, got %s for host \'%s\''
                self.bail_out(msg % (repr(this_ports), host), ERR_CONF)
            # fill in missing max
            if len(this_ports) == 1:
                this_ports.append(2 ** 16 - 1)
            # enforce bounds
            this_ports[0] = max(0, this_ports[0])
            this_ports[1] = min(2 ** 16 - 1, this_ports[1])
            # store
            stored[self.host(host, 'path')[0]] = this_ports

    def get_path (self, host, cmd):
        """Get the path to an IPython command for the given host."""
        return self.ipy_paths.get(host, {}).get(cmd, cmd)

    def run_cmd (self, cmd, log_files, ident, wait):
        """Run a command and direct its output to log files."""
        # open log files
        self.log_files[ident] = log_files
        fs = []
        for fn in log_files:
            try:
                f = open(fn, 'w')
            except IOError:
                for f in fs:
                    f.close()
                msg = 'couldn\'t open log file for writing: \'%s\''
                self.bail_out(msg % fn, ERR_IO)
            else:
                fs.append(f)
                self.open_fs.append(f)
        # run command
        if self.stopping or self._stopped:
            exit(0)
        if not self.quiet or not wait:
            print '[start]', ident
        printable_cmd = ' '.join(quote(cmd))
        if self.debug:
            print printable_cmd
        self._starting = True
        try:
            p = Popen(cmd, stdin = PIPE, stdout = fs[0], stderr = fs[1])
        except OSError:
            self._starting = False
            self.bail_out('couldn\'t run command: \'%s\'' % printable_cmd,
                          ERR_EXEC)
        self.processes[ident] = (p, wait)
        self._starting = False
        if wait:
            try:
                ret = p.wait()
            except OSError:
                # can only happen if stopped (by Launcher.stop)
                exit(0)
            for f in fs:
                f.close()
            if self.stopping or self._stopped:
                exit(0)
            elif ret != 0:
                msg = 'command returned non-zero exit status (%s): \'%s\''
                self.bail_out(msg % (ret, printable_cmd), ERR_EXEC)

    def run_on (self, host, cmd, ident, wait = False):
        """Run a command on the given host over SSH.

Returns ident.

"""
        log_files, ident = self.mk_log_files(host, ident)
        if host != 'localhost':
            cmd = ('ssh', '-tt', host, ' '.join(quote(cmd)))
        self.run_cmd(cmd, log_files, ident, wait)
        return ident

    def get_output (self, host, cmd, ident):
        """Run a command and return its stdout."""
        ident = self.run_on(host, cmd, ident, True)
        log_files = self.log_files[ident]
        try:
            f = open(log_files[0])
            try:
                out = f.read()
            finally:
                f.close()
        except IOError:
            msg = 'couldn\'t open log file for reading: \'%s\''
            self.bail_out(msg % log_files[0], ERR_IO)
        else:
            return out

    def tunnel (self, host_on, host_to, ports):
        """Open an SSH tunnel between two hosts to forward some ports.

Returns ident.

"""
        port_opts = ['-L%s:localhost:%s' % p for p in ports]
        # this will ssh to host_from first, if necessary
        # -N is better, but this makes it possible to determine success
        # also would allow for no -tt
        cmd = ';'.join(('sleep %s' % TUNNEL_WAIT,
                        'echo "[start-cluster] tunnel: success"',
                        'sleep 1000000000'))
        cmd = ['ssh', '-tt'] + port_opts + [host_to, cmd]
        return self.run_on(host_on, cmd, 'forward-port-' + host_to)

    def get_profile_dir (self, host, profile):
        """Get the directory of an IPython profile on the given host."""
        if host in self.ipy_dirs:
            # retrieve from cache
            ipy_dir = self.ipy_dirs[host]
        else:
            cmd = (self.get_path(host, 'ipython'), 'locate')
            ipy_dir = self.get_output(host, cmd, 'locate')
            ipy_dir = ipy_dir.strip().rstrip('/')
            # cache result
            self.ipy_dirs[host] = ipy_dir
        return '%s/profile_%s' % (ipy_dir, profile)

    def copy_file (self, host_from, f_from, host_to, f_to, ident):
        """Copy a file between hosts."""
        # construct hosts
        if host_from != 'localhost':
            f_from = ':'.join((host_from, f_from))
        if host_to != 'localhost':
            f_to = ':'.join((host_to, f_to))
        if host_from == host_to == 'localhost':
            # local copy
            try:
                copyfile(f_from, f_to)
            except IOError:
                msg = 'couldn\'t copy file: \'%s\' to \'%s\''
                self.bail_out(msg % (f_from, f_to), ERR_IO)
        else:
            # copy over scp
            log_files, ident = self.mk_log_files(ident)
            self.run_cmd(('scp', f_from, f_to), log_files, ident, True)

    def copy_con_file (self, host_from, profile_from, host_to, profile_to,
                       ident):
        """Copy a connection file between hosts.

"""
        # check if don't need to copy
        if (host_from, profile_from) == (host_to, profile_to):
            return
        # should only ever need to copy to each host once
        if (host_to, profile_to) in self._has_con_file[ident]:
            return
        self._has_con_file[ident].append((host_to, profile_to))
        s_ident = IDENT_TO_STR[ident]
        # get file paths
        f_from = self.get_profile_dir(host_from, profile_from)
        f_from = '%s/security/ipcontroller-%s.json' % (f_from, s_ident)
        f_to = self.get_profile_dir(host_to, profile_to)
        f_to = '%s/security/ipcontroller-%s.json' % (f_to, s_ident)
        # first copy to local temp file
        desc, f_temp = mkstemp()
        try:
            os.close(desc)
        except OSError:
            pass
        this_ident = '-'.join((host_from, 'getcon', profile_from, host_to,
                               profile_to, s_ident))
        self.copy_file(host_from, f_from, 'localhost', f_temp, this_ident)
        # edit with ports
        ports = self.get_ports(host_to, ident, 'confile')
        msg = 'copied connection file is invalid: \'%s\'' % f_temp
        try:
            f = open(f_temp)
            try:
                data = json.load(f)
            finally:
                f.close()
        except IOError:
            self.bail_out('couldn\'t read from file: \'%s\'' % f_temp, ERR_IO)
        except ValueError:
            self.bail_out(msg, ERR_IO)
        if not isinstance(data, dict):
            self.bail_out(msg, ERR_IO)
        data.update(ports)
        # stop scary warning about not being at location
        data['location'] = '127.0.0.1'
        try:
            f = open(f_temp, 'w')
            try:
                json.dump(data, f, indent = 4)
            finally:
                f.close()
        except IOError:
            self.bail_out('couldn\'t write to file: \'%s\'' % f_temp, ERR_IO)
        # copy to destination
        this_ident = '-'.join((host_to, 'setcon', profile_to, s_ident))
        self.copy_file('localhost', f_temp, host_to, f_to, this_ident)
        # clean up
        try:
            os.remove(f_temp)
        except OSError:
            pass

    def host (self, host, component = None):
        """Parse configuration host object and register aliases."""
        types = {'port': int, 'options': list, 'clients': list}
        defaults = {'port': 8888, 'profile': 'default', 'options': [],
                    'clients': []}
        if component == 'nb':
            fields = ['port', 'profile', 'options', 'clients']
        elif component == 'nbclient':
            fields = ['port']
        elif component == 'path':
            fields = []
        else:
            fields = ['profile']
        fields.insert(0, 'host')
        if isinstance(host, basestring):
            # ':'-separated fields in a string
            data = host.split(':')
        elif isinstance(host, dict):
            # field: value dict
            for k in fields:
                if k not in defaults and k not in host:
                    self.bail_out('dict-style hosts need a \'%s\' field' % k,
                                  ERR_CONF)
            data = [host.get(k, defaults.get(k)) for k in fields]
        else:
            # list of fields
            try:
                data = [v for v in host]
            except (TypeError, ValueError):
                self.bail_out('invalid host format: %s' % repr(host), ERR_CONF)
        # check types
        for i, (k, v) in enumerate(zip(fields, data)):
            if not v:
                continue
            t = types.get(k, str)
            if not isinstance(v, t):
                try:
                    v = t(v)
                except (TypeError, ValueError):
                    msg = 'invalid host format for \'%s\' field: %s'
                    self.bail_out(msg % (k, repr(v)), ERR_CONF)
            data[i] = v
        # fill in defaults
        data = data[:len(fields)]
        while len(data) < len(fields):
            data.append(None)
        for i, k in enumerate(fields):
            # check for: just appended None, or was empty in the string
            if not data[i]:
                data[i] = defaults[k]
        host = data[0]
        # get all names and add to storage
        all_hosts = self.hosts
        if host in all_hosts:
            # known host
            host = all_hosts[host]
        else:
            if host == 'localhost':
                # get hosts locally
                name = socket.gethostname()
                name, names, ips = socket.gethostbyname_ex(name)
                hosts = ['localhost', '127.0.0.1', name] + names + ips
            else:
                # get hosts remotely
                py = self.get_path(host, 'python')
                hosts = self.get_output(host, (py, '-c', '''
import socket
name, names, ips = socket.gethostbyname_ex(socket.gethostname())
print '\\n'.join([name] + names + ips)
'''), 'get-hostnames')
                hosts = [h.strip() for h in hosts.split('\n') if h.strip()]
                shost = host.split('@')
                if len(shost) == 2:
                    # got user@host: add user@ to every host
                    user = shost[0]
                    hosts = ['@'.join((user, h)) for h in hosts]
                hosts.append(host)
                host = hosts[0]
            for h in set(hosts):
                all_hosts[h] = host
        data[0] = host
        return data

    def _get_ports (self, host, mn_port, mx_port, num, used_ports, ident):
        """Get a number of suitable ports on the given host."""
        core_code = '''
mn_port = %s
mx_port = %s
need = %s
ports = set()
bad_ports = set()
pool = set(range(mn_port, mx_port + 1)) - set(used_ports)
while True:
    this_need = need - len(ports)
    if this_need == 0:
        break
    assert this_need > 0
    try:
        attempts = sample(pool, this_need)
    except ValueError:
        %s
        break
    for port in attempts:
        try:
            s = socket.socket()
            s.bind(('', port))
        except socket.error:
            bad_ports.add(port)
            pass
        else:
            s.close()
            ports.add(port)
    pool -= ports
    pool -= bad_ports
'''
        err = 'not enough open ports in the given range (%s to %s)'
        err = err % (mn_port,mx_port)
        if host == 'localhost':
            exec(core_code % (mn_port, mx_port, num, 'ports = None'))
            ports = list(ports)
        else:
            py = self.get_path(host, 'python')
            ports = self.get_output(host, (py, '-c', ('''
import socket
from random import sample
used_ports = %s
''' + core_code + '''
print '\\n'.join(str(p) for p in ports)
''') % (repr(used_ports), mn_port, mx_port, num, 'print \'%s\'' % err)), ident)
            ports = ports.strip()
            if ports == err:
                ports = None
            else:
                ports = [int(p.strip())
                         for p in ports.split('\n') if p.strip()]
        if ports is None:
            # couldn't allocate ports
            self.bail_out(err, ERR_CONF)
        return ports

    def get_ports (self, host, types, format = None):
        """Get, store and return a list of suitable ports on the given host.

format is 'confile', 'cmdline', 'ident' or 'list'.

confile: {key: port} as used in connection files.
cmdline: list of controller command-line options.
ident: {ident: port}, where ident is unique across all ports and calls for
       different hosts will use the same ident for the 'same' ports.
list: just a list of port numbers.

"""
        if format == 'confile' and types not in (ENGINE, CLIENT):
            raise ValueError('\'confile\' format requires only one component')
        elif format == 'cmdline' and not (ALL & types == ALL):
            raise ValueError('\'cmdline\' format requires all components')
        ports = self.ports.setdefault(host, {})
        # get used ports and number of needed ports
        used = []
        need = 0
        for ident, defs in PORTS.iteritems():
            ps = ports.setdefault(ident, [None] * len(defs))
            for i, (t, name) in enumerate(defs):
                if types & t:
                    # want this port
                    p = ps[i]
                    if p is None:
                        need += 1
                    else:
                        used.append(p)
        # get needed ports
        if need > 0:
            used += self._used_ports.get(host, [])
            if types == ENGINE:
                ident = 'get-ports-engine'
            elif types == CLIENT:
                ident = 'get-ports-client'
            else:
                ident = 'get-ports-all'
            mn, mx = self.port_ranges[host]
            new = self._get_ports(host, mn, mx, need, used, ident)
        else:
            new = []
        # store and retrieve ports
        wanted = {}
        for ident, defs in PORTS.iteritems():
            ps = ports[ident]
            wanted_ps = []
            for i, (t, name) in enumerate(defs):
                if types & t:
                    # want this port
                    p = ps[i]
                    if p is None:
                        ps[i] = new.pop(0)
                    wanted_ps.append((name, t, ps[i]))
            if wanted_ps:
                wanted[ident] = wanted_ps
        # convert to desired format
        if format == 'confile':
            rtn = {}
            for ps in wanted.itervalues():
                for name, t, p in ps:
                    rtn[name] = p
        elif format == 'cmdline':
            rtn = []
            for ident, ps in wanted.iteritems():
                ps = ','.join(str(p) for name, t, p in ps)
                rtn.append('--HubFactory.%s=%s' % (ident, ps))
        elif format == 'ident':
            rtn = {}
            for ident, ps in wanted.iteritems():
                for name, t, p in ps:
                    rtn[name + str(t)] = p
        else: # format == 'list'
            rtn = sum(([p for name, t, p in ps] for ps in wanted.itervalues()),
                      [])
        return rtn


if __name__ == '__main__':
    op = optparse.OptionParser(usage = USAGE, description = HELP,
                               formatter = PreformattedFormatter())
    op.add_option('-d', '--log-dir', action = 'store', type = 'string',
                  default = os.getcwd(),
                  help = 'directory to use for log files (this is not ' \
                         'created)')
    op.add_option('-p', '--preserve-logs', action = 'store_true',
                  default = False,
                  help = 'whether to skip deleting log files when exiting')
    op.add_option('-t', '--startup-delay', action = 'store', type = 'float',
                  default = 0,
                  help = 'number of seconds to wait between each component ' \
                         'started on the same host; try increasing this if ' \
                         'you have trouble with lots of engines.  This is ' \
                         'not used for local components, and can be ' \
                         'fractional (default: 0)')
    op.add_option('-q', '--quiet', action = 'store_true', default = False,
                  help = 'show less output (no [wait], and no [start] for ' \
                         'short-running commands')
    op.add_option('-b', '--debug', action = 'store_true', default = False,
                  help = 'show extra debugging output')
    options, args = op.parse_args()
    if not args:
        op.print_help()
        exit(0)
    if options.quiet and options.debug:
        op.error('--quiet and --debug options are in conflict: only one is ' \
                 'allowed')
    # start launcher
    l = Launcher(options.log_dir, options.preserve_logs, options.startup_delay,
                 options.quiet, options.debug)
    for sig in (SIGINT, SIGTERM, SIGHUP):
        signal(sig, l.stop)
    l.launch(args[0])
    # wait for a subprocess to die or a signal to this process
    l.wait()
